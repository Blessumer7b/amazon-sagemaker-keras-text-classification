{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking News: Text Classification Using Keras & TensorFlow on Amazon SageMaker\n",
    "\n",
    "This is a companion notebook to this blogpost: <TODO>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "news_dataset = pd.read_csv(os.path.join('./data', 'newsCorpora.csv'), names=column_names, header=None, delimiter='\\t')\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training and Hosting your Algorithm in Amazon SageMaker\n",
    "\n",
    "First, let's make sure we have the latest version of the Amazon SageMaker Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The following shell code shows how to build the container image using `docker build` and push the container image to ECR using `docker push`. \n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this will be the region where the notebook instance was created). If the repository doesn't exist, the script will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\r\n",
      "Starting docker:\t.[  OK  ]\r\n",
      "Sending build context to Docker daemon  459.1MB\r",
      "\r\n",
      "Step 1/9 : FROM ubuntu:16.04\n",
      " ---> f975c5035748\n",
      "Step 2/9 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 0a3444dded74\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 232ae5e100ee\n",
      "Step 4/9 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy scipy scikit-learn pandas flask gevent gunicorn tensorflow h5py &&         (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) &&         rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> 2ac9cf262b61\n",
      "Step 5/9 : ENV PYTHONUNBUFFERED TRUE\n",
      " ---> Using cache\n",
      " ---> dd5d43940e5a\n",
      "Step 6/9 : ENV PYTHONDONTWRITEBYTECODE TRUE\n",
      " ---> Using cache\n",
      " ---> 68854abd6475\n",
      "Step 7/9 : ENV PATH \"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 5c0c5ee6a722\n",
      "Step 8/9 : COPY keras_deep_nn /opt/program\n",
      " ---> Using cache\n",
      " ---> 020a7c2d4c0b\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> d87a993a5c0e\n",
      "Successfully built d87a993a5c0e\n",
      "Successfully tagged keras-deep-nn:latest\n",
      "The push refers to a repository [318556570459.dkr.ecr.us-east-1.amazonaws.com/keras-deep-nn]\n",
      "d94a7c199ed3: Preparing\n",
      "93d89f57c122: Preparing\n",
      "1dd57f8f6be4: Preparing\n",
      "db584c622b50: Preparing\n",
      "52a7ea2bb533: Preparing\n",
      "52f389ea437e: Preparing\n",
      "88888b9b1b5b: Preparing\n",
      "a94e0d5a7c40: Preparing\n",
      "52f389ea437e: Waiting\n",
      "a94e0d5a7c40: Waiting\n",
      "88888b9b1b5b: Waiting\n",
      "93d89f57c122: Layer already exists\n",
      "1dd57f8f6be4: Layer already exists\n",
      "db584c622b50: Layer already exists\n",
      "52a7ea2bb533: Layer already exists\n",
      "52f389ea437e: Layer already exists\n",
      "88888b9b1b5b: Layer already exists\n",
      "a94e0d5a7c40: Layer already exists\n",
      "d94a7c199ed3: Pushed\n",
      "latest: digest: sha256:a675814839008699d6a562f151258cd5a4f1b131727f2e16874e0ede7516f3e2 size: 1990\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-keras-text-classification\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x keras_deep_nn/train\n",
    "chmod +x keras_deep_nn/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "# On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order\n",
    "# to detect your network configuration correctly.  (This is a known issue.)\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your container packaged, you can use it to train and serve models. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'sagemaker-keras-text-classification'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "\n",
    "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3.  \n",
    "\n",
    "We can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-318556570459\n"
     ]
    }
   ],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constucted as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: keras-deep-nn-2018-04-10-23-38-49-037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................\n",
      "\u001b[31m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31m                                               TITLE  \\\u001b[0m\n",
      "\u001b[31m1  Fed official says weak data caused by weather,...   \u001b[0m\n",
      "\u001b[31m2  Fed's Charles Plosser sees high bar for change...   \u001b[0m\n",
      "\u001b[31m3  US open: Stocks fall after Fed official hints ...   \u001b[0m\n",
      "\u001b[31m4  Fed risks falling 'behind the curve', Charles ...   \u001b[0m\n",
      "\u001b[31m5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
      "\n",
      "                                                 URL          PUBLISHER  \\\u001b[0m\n",
      "\u001b[31m1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \u001b[0m\n",
      "\u001b[31m2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \u001b[0m\n",
      "\u001b[31m3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \u001b[0m\n",
      "\u001b[31m4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \u001b[0m\n",
      "\u001b[31m5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
      "\n",
      "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \u001b[0m\n",
      "\u001b[31m1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \u001b[0m\n",
      "\u001b[31m2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \u001b[0m\n",
      "\u001b[31m3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \u001b[0m\n",
      "\u001b[31m4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \u001b[0m\n",
      "\u001b[31m5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  \u001b[0m\n",
      "\u001b[31m422417\u001b[0m\n",
      "\u001b[31m422417\u001b[0m\n",
      "\u001b[31mFound 68539 unique tokens.\u001b[0m\n",
      "\u001b[31mShape of data tensor: (422417, 100)\u001b[0m\n",
      "\u001b[31mShape of label tensor: (422417, 4)\u001b[0m\n",
      "\u001b[31m2018-04-10 23:43:37.733397: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m[name: \"/device:CPU:0\"\u001b[0m\n",
      "\u001b[31mdevice_type: \"CPU\"\u001b[0m\n",
      "\u001b[31mmemory_limit: 268435456\u001b[0m\n",
      "\u001b[31mlocality {\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31mincarnation: 16141495221046527221\u001b[0m\n",
      "\u001b[31m]\u001b[0m\n",
      "\u001b[31mx_train shape:  (211208, 100)\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31membedding_1 (Embedding)      (None, 100, 100)          1000000   \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mflatten_1 (Flatten)          (None, 10000)             0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_1 (Dense)              (None, 32)                320032    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_1 (Dropout)          (None, 32)                0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_2 (Dense)              (None, 4)                 132       \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 1,320,164\u001b[0m\n",
      "\u001b[31mTrainable params: 1,320,164\u001b[0m\n",
      "\u001b[31mNon-trainable params: 0\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mTrain on 211208 samples, validate on 211209 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/1\u001b[0m\n",
      "\u001b[31m#015    32/211208 [..............................] - ETA: 21:21 - loss: 1.4822 - acc: 0.2188#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015   448/211208 [..............................] - ETA: 1:56 - loss: 1.2005 - acc: 0.5000 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015   896/211208 [..............................] - ETA: 1:10 - loss: 1.1042 - acc: 0.5502#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  1344/211208 [..............................] - ETA: 54s - loss: 1.0253 - acc: 0.5915 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  1792/211208 [..............................] - ETA: 47s - loss: 0.9823 - acc: 0.6166#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010\u001b[0m\n",
      "\u001b[31m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 42432/211208 [=====>........................] - ETA: 20s - loss: 0.6257 - acc: 0.7684#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 42880/211208 [=====>........................] - ETA: 20s - loss: 0.6254 - acc: 0.7685#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 43328/211208 [=====>........................] - ETA: 20s - loss: 0.6252 - acc: 0.7687#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 43776/211208 [=====>........................] - ETA: 20s - loss: 0.6252 - acc: 0.7685#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 44224/211208 [=====>...\u001b[0m\n",
      "\u001b[31mloss: 0.5988 - acc: 0.7810#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 84896/211208 [===========>..................] - ETA: 14s - loss: 0.5985 - acc: 0.7812#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 85344/211208 [===========>..................] - ETA: 14s - loss: 0.5982 - acc: 0.7813#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 85792/211208 [===========>..................] - ETA: 14s - loss: 0.5980 - acc: 0.7814#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 86240/211208 [===========>..................] - ETA: 14s - loss: 0.5978 - acc: 0.7815#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m8 [=================>............] - ETA: 9s - loss: 0.5860 - acc: 0.7865#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015127392/211208 [=================>............] - ETA: 9s - loss: 0.5860 - acc: 0.7866#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015127840/211208 [=================>............] - ETA: 9s - loss: 0.5861 - acc: 0.7865#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015128288/211208 [=================>............] - ETA: 9s - loss: 0.5862 - acc: 0.7865#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015128736/211208 [=================>............] - ETA: 9s - loss: 0.5860 - acc: 0.7866#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010\u001b[0m\n",
      "\u001b[31m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015169696/211208 [=======================>......] - ETA: 4s - loss: 0.5789 - acc: 0.7901#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015170144/211208 [=======================>......] - ETA: 4s - loss: 0.5788 - acc: 0.7902#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015170592/211208 [=======================>......] - ETA: 4s - loss: 0.5787 - acc: 0.7902#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015171040/211208 [=======================>......] - ETA: 4s - loss: 0.5785 - acc: 0.7903#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015171488/211208 [=======================>......] - ETA: 4s - loss: 0.5784 - acc: 0.7903#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010\u001b[0m\n",
      "\u001b[31mTraining complete. Now saving model to:  /opt/ml/model\u001b[0m\n",
      "\u001b[31mt\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 153\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-keras-text-classification'.format(account, region)\n",
    "\n",
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: keras-deep-nn-2018-04-10-23-45-47-881\n",
      "INFO:sagemaker:Creating endpoint with name keras-deep-nn-2018-04-10-23-38-49-037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer\n",
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=json_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "request = { \"input\": \"Many People Taking Antidepressants Discover They Cannot Quit\"}\n",
    "print(predictor.predict(request).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional cleanup\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
